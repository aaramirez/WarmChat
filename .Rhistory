gsub('([[:alpha:]])\\1+', '\\1', word)
## @knitr to_lowering
word<- tolower(word)
## @knitr removing_punctuations
word<- removePunctuation(word)
## @knitr removing_number
word <- removeNumbers(word)
## @knitr removing_whitespaces
wordn <- stripWhitespace(word)
return(wordn)
}
cleanSet(str)
cleanSet<- function(word){
## @knitr encoding_input
enc2utf8(word)
## @knitr removing_html
gsub("<.*?>", "", word)
## @knitr removing_urls
gsub("http[[:alnum:][:punct:]]*", "", word)
## @knir removing_rep
word <- paste(rle(strsplit(word, "")[[1]])$values, collapse="")
## @knitr to_lowering
word<- tolower(word)
## @knitr removing_punctuations
word<- removePunctuation(word)
## @knitr removing_number
word <- removeNumbers(word)
## @knitr removing_whitespaces
wordn <- stripWhitespace(word)
return(wordn)
}
cleanSet(str)
setwd("data")
save(train,badwords,file = "data.Rdata")
setwd("..")
rm("train1","str")
corpus <- Corpus(VectorSource(cleanSet(as.character(train$Comment))))
matrix <- DocumentTermMatrix(corpus)
sparse <- as.compressed.matrix(matrix)
modelMAXENT <- maxent(sparse[1:nrow(train),], as.factor(train$Insult)[1:nrow(train)])
modelMAXENT <- maxent(sparse[1:nrow(train),], as.factor(train$Insult)[1:nrow(train),])
modelMAXENT <- maxent(sparse[1:nrow(train),], as.factor(train$Insult)[1:nrow(train),])
sparse <- as.compressed.matrix(matrix)
modelMAXENT <- maxent(sparse[1:nrow(train),], as.factor(train$Insult)[1:nrow(train),])
?maxent
train$Comment
cleanSet(as.character(train$Comment))
train1 <- train
for(i in 1:nrow(train1)){
train1$Comment[i,] <- cleanSet(train1$Comment[i,])
}
for(i in 1:nrow(train1)){
train1$Comment[i] <- cleanSet(train1$Comment[i])
}
for(i in 1:nrow(train1)){
train1$Comment[i] <- cleanSet(as.character(train1$Comment[i]))
}
warnings()
View(train1)
for(i in 1:nrow(train1)){
train1$Comment[i] <- cleanSet(as.character(train$Comment[i]))
}
library('shiny')
runApp()
setwd('..')
getwd()
getwd()
setwd('..')
getwd()
library('shiny')
runApp()
runApp()
install.packages('rvest')
install.packages('rvest')
runApp()
runApp()
runApp()
runApp()
bigram_predict <- function(comm){
you_var <-c("you","your","ur","u","youre")
no_var <- c("not","no","dont","arent")
comm <- cleanComm(comm)
comm <- splitting(comm)
if(sum(comm %in% no_var)>0){
no_pos <- min(which(comm %in% no_var))
comm[no_pos]<-"not"
for(i in (no_pos+1):length(comm)){
comm[i] <- paste(comm[no_pos],comm[i],sep="-")
}
}
insult <- 0
you_badword<- paste("you",badwords,sep= "-")
if(sum(comm %in% you_var)>0){
you_pos <- min(which(comm %in% you_var))
comm[you_pos]<-"you"
for(i in (you_pos+1):length(comm)){
comm[i] <- paste(comm[you_pos],comm[i],sep="-")
}
if(sum(comm %in% you_badword)>0){
insult <- insult + 1
}
}
if(sum(comm %in% badwords)>0){
insult <- insult + 1
}
if(insult>0){
note <- 1
}else{
note <- 0
}
note
}
getwd()
save(bigram_predict,file = "models/ngramFit.Rdata")
runApp()
runApp()
runApp(launch.browser = T)
runApp(launch.browser = T)
runApp(launch.browser = T)
runApp(launch.browser = T)
runApp(launch.browser = T)
runApp(launch.browser = T)
runApp(launch.browser = T)
runApp(launch.browser = T)
runApp(launch.browser = T)
runApp(launch.browser = T)
runApp()
bigram_predict <- function(comm){
you_var <-c("you","your","ur","u","youre")
no_var <- c("not","no","dont","arent")
#comm <- cleanComm(comm)
comm <- splitting(comm)
if(sum(comm %in% no_var)>0){
no_pos <- min(which(comm %in% no_var))
comm[no_pos]<-"not"
for(i in (no_pos+1):length(comm)){
comm[i] <- paste(comm[no_pos],comm[i],sep="-")
}
}
insult <- 0
you_badword<- paste("you",badwords,sep= "-")
if(sum(comm %in% you_var)>0){
you_pos <- min(which(comm %in% you_var))
comm[you_pos]<-"you"
for(i in (you_pos+1):length(comm)){
comm[i] <- paste(comm[you_pos],comm[i],sep="-")
}
if(sum(comm %in% you_badword)>0){
insult <- insult + 1
}
}
if(sum(comm %in% badwords)>0){
insult <- insult + 1
}
if(insult>0){
note <- 1
}else{
note <- 0
}
note
}
save(bigram_predict,file = "models/ngramFit.Rdata")
runApp()
runApp()
createMatrix <- function (textColumns, language = "english", minDocFreq = 1,
maxDocFreq = Inf, minWordLength = 3, maxWordLength = Inf,
ngramLength = 1, originalMatrix = NULL, removeNumbers = FALSE,
removePunctuation = TRUE, removeSparseTerms = 0, removeStopwords = TRUE,
stemWords = FALSE, stripWhitespace = TRUE, toLower = TRUE,
weighting = weightTf)
{
stem_words <- function(x) {
split <- strsplit(x, " ")
return(wordStem(unlist(split), language = language))
}
tokenize_ngrams <- function(x, n = ngramLength) return(rownames(as.data.frame(unclass(textcnt(x,
method = "string", n = n)))))
control <- list(bounds = list(local = c(minDocFreq, maxDocFreq)),
language = language, tolower = toLower, removeNumbers = removeNumbers,
removePunctuation = removePunctuation, stopwords = removeStopwords,
stripWhitespace = stripWhitespace, wordLengths = c(minWordLength,
maxWordLength), weighting = weighting)
if (ngramLength > 1) {
control <- append(control, list(tokenize = tokenize_ngrams),
after = 7)
}
else {
control <- append(control, list(tokenize = scan_tokenizer),
after = 4)
}
if (stemWords == TRUE && ngramLength == 1)
control <- append(control, list(stemming = stem_words),
after = 7)
trainingColumn <- apply(as.matrix(textColumns), 1, paste,
collapse = " ")
trainingColumn <- sapply(as.vector(trainingColumn, mode = "character"),
iconv, to = "UTF8", sub = "byte")
corpus <- Corpus(VectorSource(trainingColumn), readerControl = list(language = language))
matrix <- DocumentTermMatrix(corpus, control = control)
if (removeSparseTerms > 0)
matrix <- removeSparseTerms(matrix, removeSparseTerms)
if (!is.null(originalMatrix)) {
terms <- colnames(originalMatrix[, which(!colnames(originalMatrix) %in%
colnames(matrix))])
weight <- 0
if (attr(weighting, "acronym") == "tf-idf")
weight <- 1e-09
amat <- matrix(weight, nrow = nrow(matrix), ncol = length(terms))
colnames(amat) <- terms
rownames(amat) <- rownames(matrix)
fixed <- as.DocumentTermMatrix(cbind(matrix[, which(colnames(matrix) %in%
colnames(originalMatrix))], amat), weighting = weighting)
matrix <- fixed
}
matrix <- matrix[, sort(colnames(matrix))]
gc()
return(matrix)
}
svm_predict <- function(testdata){
# Create the document term matrix
#matrix <- create_matrix(as.character(train$Comment))
# Configure the training data
#container <- create_container(matrix, train$Insult, trainSize = 1:2799, virgin = FALSE)
#Error in x$nrow : $ operator is invalid for atomic vectors
# Train a SVM Model
# modelSVM <- train_model(container, "SVM", kernel = "linear", cost = 1)
# Create a prediction document term matrix
#save(modelSVM,matrix,createMatrix,file = "models/svmFit.Rdata")
predMatrix <- createMatrix(c(as.character(train$Comment),testdata), originalMatrix = matrix, weighting = tm::weightTfIdf)
# Create the corresponding container
predContainer <- create_container(predMatrix,trainSize = 1:7681,testSize = 7682)
# Predict
results <- classify_model(predContainer, modelSVM)
results
}
runApp()
load("data/data.Rdata")
save(train,file = )
save(train,file = 'data/data.Rdata')
load("data/data.Rdata")
View(train)
load("models/maxentFit.Rdata")
maxent_predict('fuck you')
maxent_predict('i love')
### Makes corpora
# Function to predict a comment ~ it needs the dtm used to calculate the max-ent model and the max-ent model itself
maxent_predict <-function(comm,prob){
### Training model
#corpus <- Corpus(VectorSource(train$Comment))
### Builds a term-document matrix
#matrix <- DocumentTermMatrix(corpus)
# 10 most frequent words
#findFreqTerms(matrix, 10)
### Creates a MAXENT model [package: 'maxent']
#sparse <- as.compressed.matrix(matrix)
#modelMAXENT <- maxent(sparse[1:nrow(train),], as.factor(train$Insult)[1:nrow(train)])
#save(modelMAXENT,file = "maxentFit.Rdata")
### Predicts
testdata <- comm
predCorpus <- Corpus(VectorSource(testdata))
predMatrix <- DocumentTermMatrix(predCorpus, list(dictionary = Terms(matrix)))
predSparse <- as.compressed.matrix(predMatrix)
# Predicts
resultModel <- predict(modelMAXENT, predSparse[1,])
result <- as.numeric(resultModel[,3])
if(result >= prob){
return(1)
} else {
return(0)
}
}
save(c(matrix,modelMAXENT,maxent_predict),file = 'models/maxentFit.Rdata')
save(matrix,modelMAXENT,maxent_predict,file = 'models/maxentFit.Rdata')
maxent_predict('fuck you',0.2)
maxent_predict('fuck you',0.5)
maxent_predict('fuck you',0.4)
maxent_predict('fuck you asshole',0.4)
maxent_predict('fuck you asshole motherfucker',0.4)
maxent_predict('fuck you asshole motherfucker',0.2)
maxent_predict('fuck you asshole',0.2)
maxent_predict('fuck you',0.2)
maxent_predict('you',0.2)
maxent_predict('you asshole',0.2)
maxent_predict('asshole',0.2)
maxent_predict('asshole',0.3)
maxent_predict('asshole',0.5)
maxent_predict('asshole',0.4)
maxent_predict('asshole',0.35)
maxent_predict('asshole fuck',0.35)
load("~/Downloads/WarmChat/models/svmFit.Rdata")
svm_predict <- function(testdata){
# Create the document term matrix
#matrix <- create_matrix(as.character(train$Comment))
# Configure the training data
#container <- create_container(matrix, train$Insult, trainSize = 1:2799, virgin = FALSE)
#Error in x$nrow : $ operator is invalid for atomic vectors
# Train a SVM Model
# modelSVM <- train_model(container, "SVM", kernel = "linear", cost = 1)
# Create a prediction document term matrix
#save(modelSVM,matrix,createMatrix,file = "models/svmFit.Rdata")
predMatrix <- createMatrix(c(as.character(train$Comment),testdata), originalMatrix = matrix, weighting = tm::weightTfIdf)
# Create the corresponding container
predContainer <- create_container(predMatrix,trainSize = 1:7681,testSize = 7682)
# Predict
results <- classify_model(predContainer, modelSVM)
results
}
svm_predict('fuck')
load("~/Downloads/WarmChat/data/data.Rdata")
svm_predict('fuck')
svm_predict('fuck you')
svm_predict(list('fuck you'))
library('RTextTools')
??RTextTools
create_container
create_container
?create_container
container <- create_container(matrix,train$Insult,trainSize = 1:4000,virgin = F)
model <- train_model(container,'SVM',kernel = 'linear',cost = 1)
txt <- 'you fucking asshole'
predictionData <- list(txt)
predMatrix <- create_matrix(predictionData, originalMatrix=matrix)
library('tm')
?DocumentTermMatrix
edit(create_matrix)
predMatrix <- create_matrix(predictionData,, originalMatrix=matrix)
predMatrix <- create_matrix(predictionData,, originalMatrix=matrix)
edit(create_matrix)
c_matrix <- edit(create_matrix)
predMatrix <- c_matrix(predictionData,, originalMatrix=matrix)
predictionContainer <- create_container(predMatrix, labels=0, testSize=1, virgin=FALSE)
results <- classify_model(predictionContainer, model)
results
txt <- 'i love my friends'
predictionData <- list(txt)
predMatrix <- c_matrix(predictionData,, originalMatrix=matrix)
predictionContainer <- create_container(predMatrix, labels=0, testSize=1, virgin=FALSE)
results <- classify_model(predictionContainer, model)
results
train$Insult[1:4000]
txt <- 'love'
predictionData <- list(txt)
predMatrix <- c_matrix(predictionData,, originalMatrix=matrix)
predictionContainer <- create_container(predMatrix, labels=0, testSize=1, virgin=FALSE)
results <- classify_model(predictionContainer, model)
results
summary(train$Insult[1:4000])
sum(train$Insult[1:4000])
container <- create_container(matrix,train$Insult,trainSize = 1:6000,virgin = F)
train$Insult <- ifelse(train$Insult == 1, 1,-1)
container <- create_container(matrix,train$Insult,trainSize = 1:6000,virgin = F)
model <- train_model(container,'SVM',kernel = 'linear',cost = 1)
predictionData <- list(txt)
predMatrix <- c_matrix(predictionData,, originalMatrix=matrix)
predictionContainer <- create_container(predMatrix, labels=0, testSize=1, virgin=FALSE)
results <- classify_model(predictionContainer, model)
results
txt <- 'fuck you asshole'
predictionData <- list(txt)
predMatrix <- c_matrix(predictionData,, originalMatrix=matrix)
predictionContainer <- create_container(predMatrix, labels=0, testSize=1, virgin=FALSE)
results <- classify_model(predictionContainer, model)
results
container <- create_container(matrix,train$Insult,trainSize = 1:5000,virgin = F)
model <- train_model(container,'SVM',kernel = 'linear',cost = 1)
predictionData <- list(txt)
predMatrix <- c_matrix(predictionData,, originalMatrix=matrix)
predictionContainer <- create_container(predMatrix, labels=0, testSize=1, virgin=FALSE)
results <- classify_model(predictionContainer, model)
results
txt <- 'i love friends'
predictionData <- list(txt)
predMatrix <- c_matrix(predictionData,, originalMatrix=matrix)
predictionContainer <- create_container(predMatrix, labels=0, testSize=1, virgin=FALSE)
results <- classify_model(predictionContainer, model)
results
txt <- 'i love'
predictionData <- list(txt)
predMatrix <- c_matrix(predictionData,, originalMatrix=matrix)
predictionContainer <- create_container(predMatrix, labels=0, testSize=1, virgin=FALSE)
results <- classify_model(predictionContainer, model)
results
txt <- 'fuck'
predictionData <- list(txt)
predMatrix <- c_matrix(predictionData,, originalMatrix=matrix)
predictionContainer <- create_container(predMatrix, labels=0, testSize=1, virgin=FALSE)
results <- classify_model(predictionContainer, model)
results
txt <- 'fuck you asshole motherfucker'
predictionData <- list(txt)
predMatrix <- c_matrix(predictionData,, originalMatrix=matrix)
predictionContainer <- create_container(predMatrix, labels=0, testSize=1, virgin=FALSE)
results <- classify_model(predictionContainer, model)
results
txt <- 'the smells of roses make me feel good'
predictionData <- list(txt)
predMatrix <- c_matrix(predictionData,, originalMatrix=matrix)
predictionContainer <- create_container(predMatrix, labels=0, testSize=1, virgin=FALSE)
results <- classify_model(predictionContainer, model)
results
txt <- 'roses make me feel good'
predictionData <- list(txt)
predMatrix <- c_matrix(predictionData,, originalMatrix=matrix)
predictionContainer <- create_container(predMatrix, labels=0, testSize=1, virgin=FALSE)
results <- classify_model(predictionContainer, model)
results
txt <- 'roses feel good'
predictionData <- list(txt)
predMatrix <- c_matrix(predictionData,, originalMatrix=matrix)
predictionContainer <- create_container(predMatrix, labels=0, testSize=1, virgin=FALSE)
results <- classify_model(predictionContainer, model)
results
container <- create_container(matrix,train$Insult,trainSize = 1:5500,virgin = F)
model <- train_model(container,'SVM',kernel = 'linear',cost = 1)
predictionData <- list(txt)
predMatrix <- c_matrix(predictionData,, originalMatrix=matrix)
predictionContainer <- create_container(predMatrix, labels=0, testSize=1, virgin=FALSE)
results <- classify_model(predictionContainer, model)
results
txt
txt <- 'asshole'
predictionData <- list(txt)
predMatrix <- c_matrix(predictionData,, originalMatrix=matrix)
predictionContainer <- create_container(predMatrix, labels=0, testSize=1, virgin=FALSE)
results <- classify_model(predictionContainer, model)
results
txt <- 'fuck you asshole'
predictionData <- list(txt)
predMatrix <- c_matrix(predictionData,, originalMatrix=matrix)
predictionContainer <- create_container(predMatrix, labels=0, testSize=1, virgin=FALSE)
results <- classify_model(predictionContainer, model)
results
txt <- 'fuck you'
predictionData <- list(txt)
predMatrix <- c_matrix(predictionData,, originalMatrix=matrix)
predictionContainer <- create_container(predMatrix, labels=0, testSize=1, virgin=FALSE)
results <- classify_model(predictionContainer, model)
results
txt <- 'fucking asshole'
predictionData <- list(txt)
predMatrix <- c_matrix(predictionData,, originalMatrix=matrix)
predictionContainer <- create_container(predMatrix, labels=0, testSize=1, virgin=FALSE)
results <- classify_model(predictionContainer, model)
results
txt <- 'fucking idiot'
predictionData <- list(txt)
predMatrix <- c_matrix(predictionData,, originalMatrix=matrix)
predictionContainer <- create_container(predMatrix, labels=0, testSize=1, virgin=FALSE)
results <- classify_model(predictionContainer, model)
results
txt <- 'fuck'
predictionData <- list(txt)
predMatrix <- c_matrix(predictionData,, originalMatrix=matrix)
predictionContainer <- create_container(predMatrix, labels=0, testSize=1, virgin=FALSE)
results <- classify_model(predictionContainer, model)
results
edit(create_matrix)
results
results$SVM_LABEL
class(results$SVM_LABEL)
unlist(results$SVM_LABEL)
results$SVM_LABEL[1]
results$SVM_LABEL
?factor
as.integer(results$SVM_LABEL)
as.numeric(results$SVM_LABEL)
(results$SVM_LABEL)
attributes(results$SVM_LABEL)
levels(results$SVM_LABEL)
as.numeric(levels(results$SVM_LABEL))
install.packages('rjsonio')
install.packages('rjsonio',method = 'libcurl')
chooseCRANmirror()
install.packages('rjsonio',method = 'libcurl')
chooseCRANmirror()
shiny::runApp()
svm_predict_v2 <- function(txt){
predictionData <- list(txt)
predMatrix <- c_matrix(predictionData,, originalMatrix=matrix)
predictionContainer <- create_container(predMatrix, labels=0, testSize=1, virgin=FALSE)
results <- classify_model(predictionContainer, model)
results
as.numeric(levels(results$SVM_LABEL))
}
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
svm_predict_v2('pussy')
svm_predict_v2('ashole')
svm_predict_v2('love')
shiny::runApp()
shiny::runApp()
shiny::runApp()
load("data/data.Rdata")
?edit
load("data/data.Rdata")
save(train,file = 'data/train.Rdata')
load("models/svmFit.Rdata")
c_matrix <- edit(create_matrix)
library(RTextTools)
c_matrix <- edit(create_matrix)
load("data/train.Rdata")
container <- create_container(matrix,train$Insult,trainSize = 1:5500,virgin = F)
model <- train_model(container,'SVM',kernel = 'linear',cost = 1)
matrix
inspect(matrix[1:10,1:10])
library(tm)
inspect(matrix[1:10,1:10])
matrix
colnames(matrix)
colSums(matrix)
